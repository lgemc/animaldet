{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080493e0-f81c-4ed9-b740-75c1491138ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Loading pretrain weights\n"
     ]
    }
   ],
   "source": [
    "from rfdetr import RFDETRSmall\n",
    "\n",
    "model = RFDETRSmall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a031ae-829d-4ef7-8760-4547be9a52c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to initialize TensorBoard. Logging is turned off for this session.  Run 'pip install tensorboard' to enable logging.\n",
      "Not using distributed mode\n",
      "git:\n",
      "  sha: N/A, status: clean, branch: N/A\n",
      "\n",
      "Namespace(num_classes=7, grad_accum_steps=4, amp=True, lr=0.0001, lr_encoder=0.00015, batch_size=2, weight_decay=0.0001, epochs=10, lr_drop=100, clip_max_norm=0.1, lr_vit_layer_decay=0.8, lr_component_decay=0.7, do_benchmark=False, dropout=0, drop_path=0.0, drop_mode='standard', drop_schedule='constant', cutoff_epoch=0, pretrained_encoder=None, pretrain_weights='rf-detr-small.pth', pretrain_exclude_keys=None, pretrain_keys_modify_to_load=None, pretrained_distiller=None, encoder='dinov2_windowed_small', vit_encoder_num_layers=12, window_block_indexes=None, position_embedding='sine', out_feature_indexes=[3, 6, 9, 12], freeze_encoder=False, layer_norm=True, rms_norm=False, backbone_lora=False, force_no_pretrain=False, dec_layers=3, dim_feedforward=2048, hidden_dim=256, sa_nheads=8, ca_nheads=16, num_queries=300, group_detr=13, two_stage=True, projector_scale=['P4'], lite_refpoint_refine=True, num_select=300, dec_n_points=2, decoder_norm='LN', bbox_reparam=True, freeze_batch_norm=False, set_cost_class=2, set_cost_bbox=5, set_cost_giou=2, cls_loss_coef=1.0, bbox_loss_coef=5, giou_loss_coef=2, focal_alpha=0.25, aux_loss=True, sum_group_losses=False, use_varifocal_loss=False, use_position_supervised_loss=False, ia_bce_loss=True, dataset_file='roboflow', coco_path=None, dataset_dir='data', square_resize_div_64=True, output_dir='output', dont_save_weights=False, checkpoint_interval=10, seed=42, resume='', start_epoch=0, eval=False, use_ema=True, ema_decay=0.993, ema_tau=100, num_workers=2, device='cuda', world_size=1, dist_url='env://', sync_bn=True, fp16_eval=False, encoder_only=False, backbone_only=False, resolution=512, use_cls_token=False, multi_scale=True, expanded_scales=True, do_random_resize_via_padding=False, warmup_epochs=0.0, lr_scheduler='step', lr_min_factor=0.0, early_stopping=True, early_stopping_patience=10, early_stopping_min_delta=0.001, early_stopping_use_ema=False, gradient_checkpointing=False, patch_size=16, num_windows=2, positional_encoding_size=32, mask_downsample_ratio=4, tensorboard=True, wandb=False, project=None, run=None, class_names=['Alcelaphinae', 'Buffalo', 'Kob', 'Warthog', 'Waterbuck', 'Elephant'], run_test=True, segmentation_head=False, distributed=False)\n",
      "number of params: 31808938\n",
      "[672]\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "[672]\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "[672]\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Get benchmark\n",
      "Start training\n",
      "Grad accum steps:  4\n",
      "Total batch size:  8\n",
      "LENGTH OF DATA LOADER: 561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n",
      "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n",
      "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:345.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/561]  eta: 0:30:37  lr: 0.000100  class_error: 100.00  loss: 8.5190 (8.5190)  loss_ce: 0.9504 (0.9504)  loss_bbox: 0.3055 (0.3055)  loss_giou: 0.8636 (0.8636)  loss_ce_0: 0.9343 (0.9343)  loss_bbox_0: 0.3223 (0.3223)  loss_giou_0: 0.8793 (0.8793)  loss_ce_1: 0.9840 (0.9840)  loss_bbox_1: 0.3210 (0.3210)  loss_giou_1: 0.8298 (0.8298)  loss_ce_enc: 0.9544 (0.9544)  loss_bbox_enc: 0.3064 (0.3064)  loss_giou_enc: 0.8680 (0.8680)  loss_ce_unscaled: 0.9504 (0.9504)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0611 (0.0611)  loss_giou_unscaled: 0.4318 (0.4318)  cardinality_error_unscaled: 3899.0000 (3899.0000)  loss_ce_0_unscaled: 0.9343 (0.9343)  loss_bbox_0_unscaled: 0.0645 (0.0645)  loss_giou_0_unscaled: 0.4397 (0.4397)  cardinality_error_0_unscaled: 3876.0000 (3876.0000)  loss_ce_1_unscaled: 0.9840 (0.9840)  loss_bbox_1_unscaled: 0.0642 (0.0642)  loss_giou_1_unscaled: 0.4149 (0.4149)  cardinality_error_1_unscaled: 3899.0000 (3899.0000)  loss_ce_enc_unscaled: 0.9544 (0.9544)  loss_bbox_enc_unscaled: 0.0613 (0.0613)  loss_giou_enc_unscaled: 0.4340 (0.4340)  cardinality_error_enc_unscaled: 3899.0000 (3899.0000)  time: 3.2750  data: 0.4999  max mem: 2312\n",
      "Epoch: [0]  [ 10/561]  eta: 0:13:33  lr: 0.000100  class_error: 12.31  loss: 7.5049 (7.4703)  loss_ce: 1.0965 (1.1022)  loss_bbox: 0.1583 (0.1737)  loss_giou: 0.6228 (0.6068)  loss_ce_0: 1.0418 (1.1117)  loss_bbox_0: 0.1586 (0.1646)  loss_giou_0: 0.5214 (0.5676)  loss_ce_1: 1.0753 (1.1014)  loss_bbox_1: 0.1597 (0.1710)  loss_giou_1: 0.6360 (0.5917)  loss_ce_enc: 1.0435 (1.0649)  loss_bbox_enc: 0.1731 (0.1806)  loss_giou_enc: 0.5718 (0.6340)  loss_ce_unscaled: 1.0965 (1.1022)  class_error_unscaled: 75.0000 (59.0193)  loss_bbox_unscaled: 0.0317 (0.0347)  loss_giou_unscaled: 0.3114 (0.3034)  cardinality_error_unscaled: 2688.0000 (2757.5000)  loss_ce_0_unscaled: 1.0418 (1.1117)  loss_bbox_0_unscaled: 0.0317 (0.0329)  loss_giou_0_unscaled: 0.2607 (0.2838)  cardinality_error_0_unscaled: 3458.0000 (3117.2727)  loss_ce_1_unscaled: 1.0753 (1.1014)  loss_bbox_1_unscaled: 0.0319 (0.0342)  loss_giou_1_unscaled: 0.3180 (0.2958)  cardinality_error_1_unscaled: 2794.5000 (2829.6818)  loss_ce_enc_unscaled: 1.0435 (1.0649)  loss_bbox_enc_unscaled: 0.0346 (0.0361)  loss_giou_enc_unscaled: 0.2859 (0.3170)  cardinality_error_enc_unscaled: 3435.5000 (3129.5000)  time: 1.4756  data: 0.0750  max mem: 3099\n",
      "Epoch: [0]  [ 20/561]  eta: 0:12:33  lr: 0.000100  class_error: 75.00  loss: 7.2877 (7.2818)  loss_ce: 1.0965 (1.0972)  loss_bbox: 0.1517 (0.1623)  loss_giou: 0.5037 (0.5599)  loss_ce_0: 1.1375 (1.1080)  loss_bbox_0: 0.1354 (0.1605)  loss_giou_0: 0.4720 (0.5381)  loss_ce_1: 1.1114 (1.0929)  loss_bbox_1: 0.1509 (0.1715)  loss_giou_1: 0.5079 (0.5640)  loss_ce_enc: 1.1070 (1.0640)  loss_bbox_enc: 0.1514 (0.1735)  loss_giou_enc: 0.4870 (0.5899)  loss_ce_unscaled: 1.0965 (1.0972)  class_error_unscaled: 66.6667 (61.8062)  loss_bbox_unscaled: 0.0303 (0.0325)  loss_giou_unscaled: 0.2519 (0.2800)  cardinality_error_unscaled: 2511.5000 (2590.7381)  loss_ce_0_unscaled: 1.1375 (1.1080)  loss_bbox_0_unscaled: 0.0271 (0.0321)  loss_giou_0_unscaled: 0.2360 (0.2691)  cardinality_error_0_unscaled: 3076.5000 (2910.0476)  loss_ce_1_unscaled: 1.1114 (1.0929)  loss_bbox_1_unscaled: 0.0302 (0.0343)  loss_giou_1_unscaled: 0.2539 (0.2820)  cardinality_error_1_unscaled: 2647.0000 (2643.0476)  loss_ce_enc_unscaled: 1.1070 (1.0640)  loss_bbox_enc_unscaled: 0.0303 (0.0347)  loss_giou_enc_unscaled: 0.2435 (0.2949)  cardinality_error_enc_unscaled: 2780.0000 (2808.3810)  time: 1.2987  data: 0.0308  max mem: 3353\n",
      "Epoch: [0]  [ 30/561]  eta: 0:12:00  lr: 0.000100  class_error: 46.15  loss: 7.2146 (7.3349)  loss_ce: 0.8966 (1.0104)  loss_bbox: 0.1626 (0.1828)  loss_giou: 0.5937 (0.6382)  loss_ce_0: 0.9136 (1.0291)  loss_bbox_0: 0.1631 (0.1805)  loss_giou_0: 0.5691 (0.6197)  loss_ce_1: 0.8851 (1.0121)  loss_bbox_1: 0.1549 (0.1905)  loss_giou_1: 0.5673 (0.6393)  loss_ce_enc: 0.9200 (0.9865)  loss_bbox_enc: 0.1594 (0.1901)  loss_giou_enc: 0.5628 (0.6556)  loss_ce_unscaled: 0.8966 (1.0104)  class_error_unscaled: 50.0000 (54.9043)  loss_bbox_unscaled: 0.0325 (0.0366)  loss_giou_unscaled: 0.2969 (0.3191)  cardinality_error_unscaled: 2352.0000 (2568.4516)  loss_ce_0_unscaled: 0.9136 (1.0291)  loss_bbox_0_unscaled: 0.0326 (0.0361)  loss_giou_0_unscaled: 0.2845 (0.3099)  cardinality_error_0_unscaled: 3036.0000 (2856.0161)  loss_ce_1_unscaled: 0.8851 (1.0121)  loss_bbox_1_unscaled: 0.0310 (0.0381)  loss_giou_1_unscaled: 0.2836 (0.3197)  cardinality_error_1_unscaled: 2451.5000 (2613.0806)  loss_ce_enc_unscaled: 0.9200 (0.9865)  loss_bbox_enc_unscaled: 0.0319 (0.0380)  loss_giou_enc_unscaled: 0.2814 (0.3278)  cardinality_error_enc_unscaled: 2674.5000 (2816.1290)  time: 1.2902  data: 0.0305  max mem: 3353\n",
      "Epoch: [0]  [ 40/561]  eta: 0:11:43  lr: 0.000100  class_error: 15.38  loss: 6.5654 (7.0420)  loss_ce: 0.8052 (0.9713)  loss_bbox: 0.1631 (0.1757)  loss_giou: 0.6035 (0.6062)  loss_ce_0: 0.7940 (0.9970)  loss_bbox_0: 0.1592 (0.1726)  loss_giou_0: 0.5508 (0.5872)  loss_ce_1: 0.8174 (0.9722)  loss_bbox_1: 0.1549 (0.1834)  loss_giou_1: 0.5679 (0.6073)  loss_ce_enc: 0.7864 (0.9586)  loss_bbox_enc: 0.1614 (0.1851)  loss_giou_enc: 0.5726 (0.6254)  loss_ce_unscaled: 0.8052 (0.9713)  class_error_unscaled: 20.0000 (48.7908)  loss_bbox_unscaled: 0.0326 (0.0351)  loss_giou_unscaled: 0.3017 (0.3031)  cardinality_error_unscaled: 2900.5000 (2704.0610)  loss_ce_0_unscaled: 0.7940 (0.9970)  loss_bbox_0_unscaled: 0.0318 (0.0345)  loss_giou_0_unscaled: 0.2754 (0.2936)  cardinality_error_0_unscaled: 3283.0000 (2963.0122)  loss_ce_1_unscaled: 0.8174 (0.9722)  loss_bbox_1_unscaled: 0.0310 (0.0367)  loss_giou_1_unscaled: 0.2839 (0.3036)  cardinality_error_1_unscaled: 3093.5000 (2739.8537)  loss_ce_enc_unscaled: 0.7864 (0.9586)  loss_bbox_enc_unscaled: 0.0323 (0.0370)  loss_giou_enc_unscaled: 0.2863 (0.3127)  cardinality_error_enc_unscaled: 3158.0000 (2891.1098)  time: 1.3066  data: 0.0306  max mem: 3353\n",
      "Epoch: [0]  [ 50/561]  eta: 0:11:23  lr: 0.000100  class_error: 40.00  loss: 6.1391 (6.8742)  loss_ce: 0.8920 (0.9508)  loss_bbox: 0.1610 (0.1732)  loss_giou: 0.4663 (0.5848)  loss_ce_0: 0.9562 (0.9807)  loss_bbox_0: 0.1474 (0.1696)  loss_giou_0: 0.4427 (0.5672)  loss_ce_1: 0.8929 (0.9515)  loss_bbox_1: 0.1635 (0.1801)  loss_giou_1: 0.4868 (0.5869)  loss_ce_enc: 0.8819 (0.9363)  loss_bbox_enc: 0.1528 (0.1826)  loss_giou_enc: 0.5323 (0.6106)  loss_ce_unscaled: 0.8920 (0.9508)  class_error_unscaled: 20.0000 (44.9756)  loss_bbox_unscaled: 0.0322 (0.0346)  loss_giou_unscaled: 0.2332 (0.2924)  cardinality_error_unscaled: 3703.5000 (2808.9706)  loss_ce_0_unscaled: 0.9562 (0.9807)  loss_bbox_0_unscaled: 0.0295 (0.0339)  loss_giou_0_unscaled: 0.2213 (0.2836)  cardinality_error_0_unscaled: 3741.0000 (3004.5000)  loss_ce_1_unscaled: 0.8929 (0.9515)  loss_bbox_1_unscaled: 0.0327 (0.0360)  loss_giou_1_unscaled: 0.2434 (0.2934)  cardinality_error_1_unscaled: 3623.0000 (2823.8137)  loss_ce_enc_unscaled: 0.8819 (0.9363)  loss_bbox_enc_unscaled: 0.0306 (0.0365)  loss_giou_enc_unscaled: 0.2661 (0.3053)  cardinality_error_enc_unscaled: 3819.0000 (2937.2255)  time: 1.3116  data: 0.0292  max mem: 3353\n",
      "Epoch: [0]  [ 60/561]  eta: 0:11:04  lr: 0.000100  class_error: 5.13  loss: 6.0018 (6.7509)  loss_ce: 0.8680 (0.9381)  loss_bbox: 0.1443 (0.1659)  loss_giou: 0.4596 (0.5702)  loss_ce_0: 0.9345 (0.9760)  loss_bbox_0: 0.1428 (0.1635)  loss_giou_0: 0.4387 (0.5501)  loss_ce_1: 0.8747 (0.9412)  loss_bbox_1: 0.1438 (0.1729)  loss_giou_1: 0.4530 (0.5712)  loss_ce_enc: 0.8284 (0.9270)  loss_bbox_enc: 0.1494 (0.1766)  loss_giou_enc: 0.5137 (0.5985)  loss_ce_unscaled: 0.8680 (0.9381)  class_error_unscaled: 0.0000 (40.5449)  loss_bbox_unscaled: 0.0289 (0.0332)  loss_giou_unscaled: 0.2298 (0.2851)  cardinality_error_unscaled: 3787.5000 (2951.0902)  loss_ce_0_unscaled: 0.9345 (0.9760)  loss_bbox_0_unscaled: 0.0286 (0.0327)  loss_giou_0_unscaled: 0.2194 (0.2750)  cardinality_error_0_unscaled: 3752.0000 (3104.3443)  loss_ce_1_unscaled: 0.8747 (0.9412)  loss_bbox_1_unscaled: 0.0288 (0.0346)  loss_giou_1_unscaled: 0.2265 (0.2856)  cardinality_error_1_unscaled: 3725.0000 (2954.6475)  loss_ce_enc_unscaled: 0.8284 (0.9270)  loss_bbox_enc_unscaled: 0.0299 (0.0353)  loss_giou_enc_unscaled: 0.2568 (0.2992)  cardinality_error_enc_unscaled: 3849.5000 (3012.6721)  time: 1.2766  data: 0.0303  max mem: 3353\n",
      "Epoch: [0]  [ 70/561]  eta: 0:10:49  lr: 0.000100  class_error: 76.92  loss: 6.0370 (6.7142)  loss_ce: 0.8609 (0.9311)  loss_bbox: 0.1281 (0.1654)  loss_giou: 0.4711 (0.5693)  loss_ce_0: 0.8584 (0.9662)  loss_bbox_0: 0.1363 (0.1620)  loss_giou_0: 0.4614 (0.5509)  loss_ce_1: 0.8663 (0.9342)  loss_bbox_1: 0.1282 (0.1708)  loss_giou_1: 0.4868 (0.5707)  loss_ce_enc: 0.8429 (0.9218)  loss_bbox_enc: 0.1390 (0.1739)  loss_giou_enc: 0.5178 (0.5981)  loss_ce_unscaled: 0.8609 (0.9311)  class_error_unscaled: 5.1282 (40.1540)  loss_bbox_unscaled: 0.0256 (0.0331)  loss_giou_unscaled: 0.2356 (0.2846)  cardinality_error_unscaled: 3854.0000 (3028.9648)  loss_ce_0_unscaled: 0.8584 (0.9662)  loss_bbox_0_unscaled: 0.0273 (0.0324)  loss_giou_0_unscaled: 0.2307 (0.2754)  cardinality_error_0_unscaled: 3812.5000 (3148.1056)  loss_ce_1_unscaled: 0.8663 (0.9342)  loss_bbox_1_unscaled: 0.0256 (0.0342)  loss_giou_1_unscaled: 0.2434 (0.2853)  cardinality_error_1_unscaled: 3826.0000 (3012.1690)  loss_ce_enc_unscaled: 0.8429 (0.9218)  loss_bbox_enc_unscaled: 0.0278 (0.0348)  loss_giou_enc_unscaled: 0.2589 (0.2990)  cardinality_error_enc_unscaled: 3844.0000 (3039.7606)  time: 1.2827  data: 0.0312  max mem: 3353\n",
      "Epoch: [0]  [ 80/561]  eta: 0:10:31  lr: 0.000100  class_error: 50.00  loss: 6.2693 (6.6664)  loss_ce: 0.8072 (0.9078)  loss_bbox: 0.1357 (0.1666)  loss_giou: 0.5358 (0.5777)  loss_ce_0: 0.8195 (0.9421)  loss_bbox_0: 0.1363 (0.1621)  loss_giou_0: 0.5217 (0.5597)  loss_ce_1: 0.7938 (0.9103)  loss_bbox_1: 0.1370 (0.1719)  loss_giou_1: 0.5536 (0.5822)  loss_ce_enc: 0.8073 (0.9010)  loss_bbox_enc: 0.1435 (0.1755)  loss_giou_enc: 0.5907 (0.6094)  loss_ce_unscaled: 0.8072 (0.9078)  class_error_unscaled: 25.0000 (37.9270)  loss_bbox_unscaled: 0.0271 (0.0333)  loss_giou_unscaled: 0.2679 (0.2889)  cardinality_error_unscaled: 3611.5000 (3074.9321)  loss_ce_0_unscaled: 0.8195 (0.9421)  loss_bbox_0_unscaled: 0.0273 (0.0324)  loss_giou_0_unscaled: 0.2609 (0.2799)  cardinality_error_0_unscaled: 3660.0000 (3172.4383)  loss_ce_1_unscaled: 0.7938 (0.9103)  loss_bbox_1_unscaled: 0.0274 (0.0344)  loss_giou_1_unscaled: 0.2768 (0.2911)  cardinality_error_1_unscaled: 3601.5000 (3044.7716)  loss_ce_enc_unscaled: 0.8073 (0.9010)  loss_bbox_enc_unscaled: 0.0287 (0.0351)  loss_giou_enc_unscaled: 0.2953 (0.3047)  cardinality_error_enc_unscaled: 3652.0000 (3034.0556)  time: 1.2691  data: 0.0294  max mem: 3353\n",
      "Epoch: [0]  [ 90/561]  eta: 0:10:13  lr: 0.000100  class_error: 0.00  loss: 6.0060 (6.5400)  loss_ce: 0.7552 (0.8907)  loss_bbox: 0.1108 (0.1614)  loss_giou: 0.5358 (0.5676)  loss_ce_0: 0.8058 (0.9234)  loss_bbox_0: 0.1118 (0.1575)  loss_giou_0: 0.5217 (0.5526)  loss_ce_1: 0.7454 (0.8929)  loss_bbox_1: 0.1155 (0.1663)  loss_giou_1: 0.5536 (0.5723)  loss_ce_enc: 0.7544 (0.8868)  loss_bbox_enc: 0.1167 (0.1705)  loss_giou_enc: 0.5352 (0.5981)  loss_ce_unscaled: 0.7552 (0.8907)  class_error_unscaled: 0.0000 (34.4286)  loss_bbox_unscaled: 0.0222 (0.0323)  loss_giou_unscaled: 0.2679 (0.2838)  cardinality_error_unscaled: 3318.0000 (3068.2308)  loss_ce_0_unscaled: 0.8058 (0.9234)  loss_bbox_0_unscaled: 0.0224 (0.0315)  loss_giou_0_unscaled: 0.2609 (0.2763)  cardinality_error_0_unscaled: 3278.5000 (3153.5879)  loss_ce_1_unscaled: 0.7454 (0.8929)  loss_bbox_1_unscaled: 0.0231 (0.0333)  loss_giou_1_unscaled: 0.2768 (0.2862)  cardinality_error_1_unscaled: 3105.0000 (3023.5385)  loss_ce_enc_unscaled: 0.7544 (0.8868)  loss_bbox_enc_unscaled: 0.0233 (0.0341)  loss_giou_enc_unscaled: 0.2676 (0.2990)  cardinality_error_enc_unscaled: 2347.0000 (2985.5495)  time: 1.2291  data: 0.0284  max mem: 3353\n",
      "Epoch: [0]  [100/561]  eta: 0:09:58  lr: 0.000100  class_error: 33.33  loss: 5.5321 (6.4462)  loss_ce: 0.7077 (0.8710)  loss_bbox: 0.1182 (0.1597)  loss_giou: 0.4098 (0.5633)  loss_ce_0: 0.7079 (0.9016)  loss_bbox_0: 0.1196 (0.1590)  loss_giou_0: 0.4222 (0.5539)  loss_ce_1: 0.7228 (0.8715)  loss_bbox_1: 0.1155 (0.1652)  loss_giou_1: 0.4281 (0.5709)  loss_ce_enc: 0.7163 (0.8643)  loss_bbox_enc: 0.1223 (0.1696)  loss_giou_enc: 0.4427 (0.5963)  loss_ce_unscaled: 0.7077 (0.8710)  class_error_unscaled: 0.0000 (32.8160)  loss_bbox_unscaled: 0.0236 (0.0319)  loss_giou_unscaled: 0.2049 (0.2817)  cardinality_error_unscaled: 3634.0000 (3095.9109)  loss_ce_0_unscaled: 0.7079 (0.9016)  loss_bbox_0_unscaled: 0.0239 (0.0318)  loss_giou_0_unscaled: 0.2111 (0.2769)  cardinality_error_0_unscaled: 3420.0000 (3155.3317)  loss_ce_1_unscaled: 0.7228 (0.8715)  loss_bbox_1_unscaled: 0.0231 (0.0330)  loss_giou_1_unscaled: 0.2140 (0.2854)  cardinality_error_1_unscaled: 3447.0000 (3038.3317)  loss_ce_enc_unscaled: 0.7163 (0.8643)  loss_bbox_enc_unscaled: 0.0245 (0.0339)  loss_giou_enc_unscaled: 0.2213 (0.2982)  cardinality_error_enc_unscaled: 3501.0000 (2998.1733)  time: 1.2432  data: 0.0305  max mem: 3353\n",
      "Epoch: [0]  [110/561]  eta: 0:09:43  lr: 0.000100  class_error: 0.00  loss: 5.2764 (6.3600)  loss_ce: 0.6858 (0.8589)  loss_bbox: 0.1250 (0.1570)  loss_giou: 0.4115 (0.5544)  loss_ce_0: 0.7100 (0.8909)  loss_bbox_0: 0.1277 (0.1572)  loss_giou_0: 0.4228 (0.5470)  loss_ce_1: 0.6521 (0.8598)  loss_bbox_1: 0.1276 (0.1623)  loss_giou_1: 0.4428 (0.5618)  loss_ce_enc: 0.7039 (0.8533)  loss_bbox_enc: 0.1304 (0.1676)  loss_giou_enc: 0.4451 (0.5896)  loss_ce_unscaled: 0.6858 (0.8589)  class_error_unscaled: 0.0000 (32.0772)  loss_bbox_unscaled: 0.0250 (0.0314)  loss_giou_unscaled: 0.2057 (0.2772)  cardinality_error_unscaled: 3778.0000 (3138.4955)  loss_ce_0_unscaled: 0.7100 (0.8909)  loss_bbox_0_unscaled: 0.0255 (0.0314)  loss_giou_0_unscaled: 0.2114 (0.2735)  cardinality_error_0_unscaled: 3699.0000 (3177.6712)  loss_ce_1_unscaled: 0.6521 (0.8598)  loss_bbox_1_unscaled: 0.0255 (0.0325)  loss_giou_1_unscaled: 0.2214 (0.2809)  cardinality_error_1_unscaled: 3682.5000 (3077.6486)  loss_ce_enc_unscaled: 0.7039 (0.8533)  loss_bbox_enc_unscaled: 0.0261 (0.0335)  loss_giou_enc_unscaled: 0.2226 (0.2948)  cardinality_error_enc_unscaled: 3753.5000 (3036.3964)  time: 1.2606  data: 0.0319  max mem: 3353\n",
      "Epoch: [0]  [120/561]  eta: 0:09:30  lr: 0.000100  class_error: 0.00  loss: 5.0791 (6.2561)  loss_ce: 0.6858 (0.8467)  loss_bbox: 0.0996 (0.1525)  loss_giou: 0.4333 (0.5445)  loss_ce_0: 0.7980 (0.8823)  loss_bbox_0: 0.1073 (0.1529)  loss_giou_0: 0.4228 (0.5374)  loss_ce_1: 0.6695 (0.8469)  loss_bbox_1: 0.1028 (0.1574)  loss_giou_1: 0.4337 (0.5510)  loss_ce_enc: 0.7682 (0.8418)  loss_bbox_enc: 0.1069 (0.1629)  loss_giou_enc: 0.4416 (0.5798)  loss_ce_unscaled: 0.6858 (0.8467)  class_error_unscaled: 0.0000 (30.1318)  loss_bbox_unscaled: 0.0199 (0.0305)  loss_giou_unscaled: 0.2166 (0.2722)  cardinality_error_unscaled: 3734.0000 (3150.3926)  loss_ce_0_unscaled: 0.7980 (0.8823)  loss_bbox_0_unscaled: 0.0215 (0.0306)  loss_giou_0_unscaled: 0.2114 (0.2687)  cardinality_error_0_unscaled: 3751.0000 (3186.8306)  loss_ce_1_unscaled: 0.6695 (0.8469)  loss_bbox_1_unscaled: 0.0206 (0.0315)  loss_giou_1_unscaled: 0.2168 (0.2755)  cardinality_error_1_unscaled: 3743.0000 (3092.2314)  loss_ce_enc_unscaled: 0.7682 (0.8418)  loss_bbox_enc_unscaled: 0.0214 (0.0326)  loss_giou_enc_unscaled: 0.2208 (0.2899)  cardinality_error_enc_unscaled: 3853.5000 (3059.7769)  time: 1.2620  data: 0.0304  max mem: 3353\n",
      "Epoch: [0]  [130/561]  eta: 0:09:16  lr: 0.000100  class_error: 0.00  loss: 5.0791 (6.1658)  loss_ce: 0.6265 (0.8338)  loss_bbox: 0.0996 (0.1497)  loss_giou: 0.4488 (0.5387)  loss_ce_0: 0.6991 (0.8682)  loss_bbox_0: 0.1080 (0.1498)  loss_giou_0: 0.4244 (0.5318)  loss_ce_1: 0.6239 (0.8330)  loss_bbox_1: 0.1028 (0.1538)  loss_giou_1: 0.4337 (0.5437)  loss_ce_enc: 0.6396 (0.8299)  loss_bbox_enc: 0.1069 (0.1600)  loss_giou_enc: 0.4416 (0.5734)  loss_ce_unscaled: 0.6265 (0.8338)  class_error_unscaled: 0.0000 (28.9767)  loss_bbox_unscaled: 0.0199 (0.0299)  loss_giou_unscaled: 0.2244 (0.2693)  cardinality_error_unscaled: 3304.5000 (3080.0038)  loss_ce_0_unscaled: 0.6991 (0.8682)  loss_bbox_0_unscaled: 0.0216 (0.0300)  loss_giou_0_unscaled: 0.2122 (0.2659)  cardinality_error_0_unscaled: 3724.5000 (3131.3550)  loss_ce_1_unscaled: 0.6239 (0.8330)  loss_bbox_1_unscaled: 0.0206 (0.0308)  loss_giou_1_unscaled: 0.2168 (0.2718)  cardinality_error_1_unscaled: 3604.5000 (3033.8931)  loss_ce_enc_unscaled: 0.6396 (0.8299)  loss_bbox_enc_unscaled: 0.0214 (0.0320)  loss_giou_enc_unscaled: 0.2208 (0.2867)  cardinality_error_enc_unscaled: 3816.0000 (3019.1374)  time: 1.2660  data: 0.0294  max mem: 3353\n",
      "Epoch: [0]  [140/561]  eta: 0:09:02  lr: 0.000100  class_error: 85.71  loss: 5.6996 (6.1659)  loss_ce: 0.6390 (0.8379)  loss_bbox: 0.1185 (0.1482)  loss_giou: 0.4673 (0.5354)  loss_ce_0: 0.6889 (0.8686)  loss_bbox_0: 0.1173 (0.1491)  loss_giou_0: 0.4761 (0.5301)  loss_ce_1: 0.6299 (0.8368)  loss_bbox_1: 0.1144 (0.1527)  loss_giou_1: 0.4695 (0.5410)  loss_ce_enc: 0.6396 (0.8369)  loss_bbox_enc: 0.1257 (0.1596)  loss_giou_enc: 0.4707 (0.5696)  loss_ce_unscaled: 0.6390 (0.8379)  class_error_unscaled: 0.0000 (28.9480)  loss_bbox_unscaled: 0.0237 (0.0296)  loss_giou_unscaled: 0.2337 (0.2677)  cardinality_error_unscaled: 2048.5000 (3046.7482)  loss_ce_0_unscaled: 0.6889 (0.8686)  loss_bbox_0_unscaled: 0.0235 (0.0298)  loss_giou_0_unscaled: 0.2380 (0.2650)  cardinality_error_0_unscaled: 2180.5000 (3102.1277)  loss_ce_1_unscaled: 0.6299 (0.8368)  loss_bbox_1_unscaled: 0.0229 (0.0305)  loss_giou_1_unscaled: 0.2347 (0.2705)  cardinality_error_1_unscaled: 2076.0000 (3006.8972)  loss_ce_enc_unscaled: 0.6396 (0.8369)  loss_bbox_enc_unscaled: 0.0251 (0.0319)  loss_giou_enc_unscaled: 0.2353 (0.2848)  cardinality_error_enc_unscaled: 2102.0000 (2998.8511)  time: 1.2684  data: 0.0291  max mem: 3353\n",
      "Epoch: [0]  [150/561]  eta: 0:08:50  lr: 0.000100  class_error: 0.00  loss: 5.6996 (6.1198)  loss_ce: 0.6830 (0.8347)  loss_bbox: 0.1119 (0.1460)  loss_giou: 0.3982 (0.5283)  loss_ce_0: 0.7521 (0.8647)  loss_bbox_0: 0.1155 (0.1473)  loss_giou_0: 0.4121 (0.5247)  loss_ce_1: 0.6941 (0.8330)  loss_bbox_1: 0.1133 (0.1507)  loss_giou_1: 0.4192 (0.5343)  loss_ce_enc: 0.7335 (0.8342)  loss_bbox_enc: 0.1210 (0.1579)  loss_giou_enc: 0.4288 (0.5640)  loss_ce_unscaled: 0.6830 (0.8347)  class_error_unscaled: 0.0000 (28.1347)  loss_bbox_unscaled: 0.0224 (0.0292)  loss_giou_unscaled: 0.1991 (0.2642)  cardinality_error_unscaled: 2031.5000 (3002.4669)  loss_ce_0_unscaled: 0.7521 (0.8647)  loss_bbox_0_unscaled: 0.0231 (0.0295)  loss_giou_0_unscaled: 0.2060 (0.2623)  cardinality_error_0_unscaled: 2314.5000 (3060.9669)  loss_ce_1_unscaled: 0.6941 (0.8330)  loss_bbox_1_unscaled: 0.0227 (0.0301)  loss_giou_1_unscaled: 0.2096 (0.2671)  cardinality_error_1_unscaled: 2140.5000 (2966.6325)  loss_ce_enc_unscaled: 0.7335 (0.8342)  loss_bbox_enc_unscaled: 0.0242 (0.0316)  loss_giou_enc_unscaled: 0.2144 (0.2820)  cardinality_error_enc_unscaled: 2102.0000 (2966.4967)  time: 1.2864  data: 0.0290  max mem: 3353\n",
      "Epoch: [0]  [160/561]  eta: 0:08:38  lr: 0.000100  class_error: 0.00  loss: 5.3454 (6.1149)  loss_ce: 0.6973 (0.8335)  loss_bbox: 0.1119 (0.1463)  loss_giou: 0.4350 (0.5277)  loss_ce_0: 0.7534 (0.8628)  loss_bbox_0: 0.1222 (0.1478)  loss_giou_0: 0.4415 (0.5250)  loss_ce_1: 0.6985 (0.8318)  loss_bbox_1: 0.1203 (0.1509)  loss_giou_1: 0.4411 (0.5335)  loss_ce_enc: 0.7519 (0.8342)  loss_bbox_enc: 0.1304 (0.1580)  loss_giou_enc: 0.4876 (0.5634)  loss_ce_unscaled: 0.6973 (0.8335)  class_error_unscaled: 0.0000 (27.7536)  loss_bbox_unscaled: 0.0224 (0.0293)  loss_giou_unscaled: 0.2175 (0.2638)  cardinality_error_unscaled: 3366.0000 (3005.2702)  loss_ce_0_unscaled: 0.7534 (0.8628)  loss_bbox_0_unscaled: 0.0244 (0.0296)  loss_giou_0_unscaled: 0.2208 (0.2625)  cardinality_error_0_unscaled: 3599.5000 (3070.4317)  loss_ce_1_unscaled: 0.6985 (0.8318)  loss_bbox_1_unscaled: 0.0241 (0.0302)  loss_giou_1_unscaled: 0.2205 (0.2668)  cardinality_error_1_unscaled: 3269.0000 (2969.2795)  loss_ce_enc_unscaled: 0.7519 (0.8342)  loss_bbox_enc_unscaled: 0.0261 (0.0316)  loss_giou_enc_unscaled: 0.2438 (0.2817)  cardinality_error_enc_unscaled: 3849.0000 (2987.4969)  time: 1.3141  data: 0.0300  max mem: 3353\n",
      "Epoch: [0]  [170/561]  eta: 0:08:23  lr: 0.000100  class_error: 0.00  loss: 5.7553 (6.1015)  loss_ce: 0.7693 (0.8294)  loss_bbox: 0.1236 (0.1459)  loss_giou: 0.5232 (0.5270)  loss_ce_0: 0.7269 (0.8573)  loss_bbox_0: 0.1309 (0.1482)  loss_giou_0: 0.5765 (0.5277)  loss_ce_1: 0.7628 (0.8280)  loss_bbox_1: 0.1319 (0.1503)  loss_giou_1: 0.5509 (0.5335)  loss_ce_enc: 0.7581 (0.8301)  loss_bbox_enc: 0.1515 (0.1584)  loss_giou_enc: 0.5629 (0.5657)  loss_ce_unscaled: 0.7693 (0.8294)  class_error_unscaled: 0.0000 (26.7739)  loss_bbox_unscaled: 0.0247 (0.0292)  loss_giou_unscaled: 0.2616 (0.2635)  cardinality_error_unscaled: 3366.0000 (2977.2690)  loss_ce_0_unscaled: 0.7269 (0.8573)  loss_bbox_0_unscaled: 0.0262 (0.0296)  loss_giou_0_unscaled: 0.2882 (0.2638)  cardinality_error_0_unscaled: 3599.5000 (3038.8275)  loss_ce_1_unscaled: 0.7628 (0.8280)  loss_bbox_1_unscaled: 0.0264 (0.0301)  loss_giou_1_unscaled: 0.2754 (0.2667)  cardinality_error_1_unscaled: 3269.0000 (2941.3801)  loss_ce_enc_unscaled: 0.7581 (0.8301)  loss_bbox_enc_unscaled: 0.0303 (0.0317)  loss_giou_enc_unscaled: 0.2814 (0.2829)  cardinality_error_enc_unscaled: 3849.0000 (2962.2251)  time: 1.2827  data: 0.0299  max mem: 3353\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    dataset_dir='data',\n",
    "    epochs=10,\n",
    "    batch_size=2,\n",
    "    grad_accum_steps=4,\n",
    "    lr=1e-4,\n",
    "    output_dir='output',\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb8cc05-8291-41b0-b7b3-f5c0b68f8343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Using patch size 16 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
      "Loading pretrain weights\n"
     ]
    }
   ],
   "source": [
    "model = RFDETRSmall(pretrain_weights='output/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279fe7b8-0202-4633-ade2-f80ff2c5b91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([], shape=(0, 4), dtype=float32), mask=None, confidence=array([], dtype=float32), class_id=array([], dtype=int64), tracker_id=None, data={}, metadata={})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('data/train/000113a692ba61cd55ea3acb9c2f9c41709710a1_0.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c6fe23-b4f2-4692-bdd3-a62473608a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
