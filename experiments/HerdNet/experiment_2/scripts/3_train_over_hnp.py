# This script trains the HerdNet model on stage 2 data using a specified training and validation dataset.
# Training patches are all those patches where the model generated by stage 1 detected at least one animal, even if
# they have low confidence.
# Validation is performed on the full validation image using a stitching approach.
import sys

args = sys.argv

if len(args) != 7:
    print("Usage: python 3_train_over_hnp.py <work_dir> <root_dir> <train_csv> <val_csv> <val_root_dir> <pth_path>")
    sys.exit(1)

import os
from animaloc.utils.seed import set_seed
import albumentations as A
from animaloc.datasets import CSVDataset, FolderDataset
from animaloc.data.transforms import MultiTransformsWrapper, DownSample, PointsToMask, FIDT
from torch.utils.data import DataLoader
from animaloc.models import HerdNet, LossWrapper, load_model
from torch import Tensor
from animaloc.train.losses import FocalLoss
from torch.nn import CrossEntropyLoss
from torch.optim import Adam
from animaloc.train import Trainer
from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator
import torch
import wandb

set_seed(9292)

patch_size = 512
num_classes = 7
down_ratio = 2
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

work_dir = args[1]  # output directory, example: '/workspace/data_stage_2'
os.makedirs(work_dir, exist_ok=True)
root_dir = args[2]  # example: '/workspace/data/hnp_patches_plus_train_patches'
train_dataset = FolderDataset(
    csv_file = args[3],  # example: '/workspace/data/train_patches.csv',
    root_dir = root_dir,
    albu_transforms = [
        A.VerticalFlip(p=0.5),
        A.HorizontalFlip(p=0.5),
        A.RandomRotate90(p=0.5),
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.2),
        A.Blur(blur_limit=15, p=0.2),
        A.Normalize(
            mean=(0.485, 0.456, 0.406),
            std=(0.229, 0.224, 0.225),
        )
        ],
    end_transforms = [MultiTransformsWrapper([
        FIDT(num_classes=num_classes, add_bg=False, down_ratio=down_ratio),
        PointsToMask(radius=2, num_classes=num_classes, squeeze=True, down_ratio=int(patch_size//16))
        ])]
    )

val_dataset = CSVDataset(
    csv_file = args[4],  # example: '/workspace/data/val.csv',
    root_dir = args[5],  # example: '/workspace/data/val',
    albu_transforms = [A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))],
    end_transforms = [DownSample(down_ratio=down_ratio, anno_type='point')]
)

train_dataloader = DataLoader(
    dataset = train_dataset,
    batch_size = 4,
    shuffle = True,
    num_workers=45
)

val_dataloader = DataLoader(
    dataset = val_dataset,
    batch_size = 1,
    shuffle = False,
    num_workers=30
)

herdnet = HerdNet(num_classes=num_classes, down_ratio=down_ratio).to(device)
herdnet = load_model(herdnet, pth_path=args[6])  # example: "/workspace/data/latest_model_100.pth"

weight = Tensor([0.1, 1.0, 2.0, 1.0, 6.0, 12.0, 1.0]).to(device) # herdnet weights

losses = [
    {'loss': FocalLoss(reduction='mean', normalize=False), 'idx': 0, 'idy': 0, 'lambda': 1.0, 'name': 'focal_loss'},
    {'loss': CrossEntropyLoss(reduction='mean', weight=weight), 'idx': 1, 'idy': 1, 'lambda': 1.0, 'name': 'ce_loss', 'from_torch': True}
    ]

herdnet = LossWrapper(herdnet, losses=losses)
lr = 1e-6
weight_decay = 5e-4
epochs = 50

optimizer = Adam(params=herdnet.parameters(), lr=lr, weight_decay=weight_decay, )
metrics = PointsMetrics(radius=5, num_classes=num_classes) # radius for herdnet data

stitcher = HerdNetStitcher(
    model=herdnet,
    size=(patch_size,patch_size),
    overlap=160,
    down_ratio=down_ratio,
    reduction='mean',
    up=False
)

evaluator = HerdNetEvaluator(
    model=herdnet,
    dataloader=val_dataloader,
    metrics=metrics,
    stitcher=stitcher,
    work_dir=work_dir,
    header='validation',
    print_freq=10,
    lmds_kwargs={
        "kernel_size": (3,3),
        "adapt_ts": 0.3,
    }
    )

trainer = Trainer(
    model=herdnet,
    train_dataloader=train_dataloader,
    optimizer=optimizer,
    num_epochs=epochs,
    evaluator=evaluator,
    work_dir=work_dir,
    print_freq=100,
    valid_freq=10,
    auto_lr={
        "mode": "max",
        "patience": 10,
        "threshold": 1e-4,
        "threshold_mode": "rel",
        "cooldown": 10,
        "min_lr": 1e-6,
    },
)

wandb.init(project='herdnet')
trainer.start(warmup_iters=1, checkpoints='best', select='max', validate_on='f1_score', wandb_flag=True)
