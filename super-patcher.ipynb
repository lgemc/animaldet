{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-19T21:05:50.431921Z",
     "start_time": "2025-10-19T21:05:50.427539Z"
    }
   },
   "source": [
    "target_csv_val = \"./general_dataset/groundtruth/csv/val_big_size_A_B_E_K_WH_WB.csv\"\n",
    "target_images_val = \"./general_dataset/val\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:06:16.813726Z",
     "start_time": "2025-10-19T21:06:16.810544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_csv_train = \"./general_dataset/groundtruth/csv/train_big_size_A_B_E_K_WH_WB.csv\"\n",
    "target_images_train = \"./general_dataset/train\""
   ],
   "id": "737139fc6cc10a47",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:26:44.885761Z",
     "start_time": "2025-10-19T21:26:44.882556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_csv_test = \"./general_dataset/groundtruth/csv/test_big_size_A_B_E_K_WH_WB.csv\"\n",
    "target_images_test = \"./general_dataset/test\""
   ],
   "id": "b8fdd33843f2a8b3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:39:33.158342Z",
     "start_time": "2025-10-19T21:39:32.817023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_annotations(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Process annotation CSV and save in standardized format.\n",
    "\n",
    "    Args:\n",
    "        input_csv (str): Path to input CSV file\n",
    "        output_csv (str): Path to output CSV file\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed dataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Rename columns\n",
    "    df[\"images\"] = df[\"Image\"]\n",
    "    df[\"labels\"] = df[\"Label\"]\n",
    "    df[\"x_min\"] = df[\"x1\"]\n",
    "    df[\"x_max\"] = df[\"x2\"]\n",
    "    df[\"y_min\"] = df[\"y1\"]\n",
    "    df[\"y_max\"] = df[\"y2\"]\n",
    "\n",
    "    # Select only needed columns\n",
    "    df = df[['images', 'labels', 'x_min', 'x_max', 'y_min', 'y_max']]\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Processed {len(df)} annotations from {input_csv}\")\n",
    "    print(f\"Saved to {output_csv}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Process all three datasets\n",
    "df_val = process_annotations(target_csv_val, \"./annotations_val.csv\")\n",
    "df_train = process_annotations(target_csv_train, \"./annotations_train.csv\")\n",
    "df_test = process_annotations(target_csv_test, \"./annotations_test.csv\")\n",
    "\n",
    "# Display one of them to verify\n",
    "df_val"
   ],
   "id": "26282de05d443025",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_csv_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 37\u001B[0m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Process all three datasets\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m df_val \u001B[38;5;241m=\u001B[39m process_annotations(\u001B[43mtarget_csv_val\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./annotations_val.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     38\u001B[0m df_train \u001B[38;5;241m=\u001B[39m process_annotations(target_csv_train, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./annotations_train.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     39\u001B[0m df_test \u001B[38;5;241m=\u001B[39m process_annotations(target_csv_test, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./annotations_test.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'target_csv_val' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T04:15:04.190408Z",
     "start_time": "2025-10-19T04:13:59.884763Z"
    }
   },
   "cell_type": "code",
   "source": "#!python ../tools/patcher.py ./groundtruth/val 512 512 0 ./patches -csv ./annotations.csv -min 0.0 -all False",
   "id": "4a5ef08275b8da02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "Creating the buffer: 100%|████████████████████| 111/111 [00:12<00:00,  8.85it/s]\r\n",
      "Exporting patches: 100%|██████████████████████| 111/111 [00:47<00:00,  2.32it/s]\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-19T21:27:39.705745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download and install the code\n",
    "import sys\n",
    "\n",
    "!git clone https://github.com/Alexandre-Delplanque/HerdNet\n",
    "!cd 'HerdNet' && python setup.py install\n",
    "\n",
    "sys.path.append('./HerdNet')\n",
    "\n",
    "# Patcher parameters\n",
    "patch_width = 512\n",
    "patch_height = 512\n",
    "overlap = 0\n",
    "output_base_dir = \"./patches\"\n",
    "min_val = 0.0\n",
    "flag = False\n",
    "\n",
    "# Process validation set\n",
    "output_dir_val = f\"{output_base_dir}/valid\"\n",
    "!rm -rf {output_dir_val}\n",
    "!mkdir -p {output_dir_val}\n",
    "!python ../tools/patcher.py {target_images_val} {patch_width} {patch_height} {overlap} {output_dir_val} -csv ./annotations_val.csv -min {min_val} -all {flag}\n",
    "\n",
    "# Process training set\n",
    "output_dir_train = f\"{output_base_dir}/train\"\n",
    "!rm -rf {output_dir_train}\n",
    "!mkdir -p {output_dir_train}\n",
    "!python ../tools/patcher.py {target_images_train} {patch_width} {patch_height} {overlap} {output_dir_train} -csv ./annotations_train.csv -min {min_val} -all {flag}\n",
    "\n",
    "# Process test set\n",
    "output_dir_test = f\"{output_base_dir}/test\"\n",
    "!rm -rf {output_dir_test}\n",
    "!mkdir -p {output_dir_test}\n",
    "!python ../tools/patcher.py {target_images_test} {patch_width} {patch_height} {overlap} {output_dir_test} -csv ./annotations_test.csv -min {min_val} -all {flag}"
   ],
   "id": "a78cc36c4928da45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "Creating the buffer: 100%|████████████████████| 258/258 [00:27<00:00,  9.25it/s]\r\n",
      "Exporting patches:  18%|████                   | 46/258 [00:20<01:28,  2.38it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T04:29:07.052620Z",
     "start_time": "2025-10-19T04:29:06.204377Z"
    }
   },
   "cell_type": "code",
   "source": "!python ../tools/view.py ./patches ./patches/gt.csv # needs mongodb running on 27017",
   "id": "8c3b274d057f87d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncaught exception\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/core/odm/database.py\", line 79, in establish_db_conn\r\n",
      "    _db_service = fos.DatabaseService()\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/core/service.py\", line 80, in __init__\r\n",
      "    self.start()\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/core/service.py\", line 231, in start\r\n",
      "    super().start()\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/core/service.py\", line 118, in start\r\n",
      "    + self.command,\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/core/service.py\", line 260, in command\r\n",
      "    DatabaseService.find_mongod(),\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/core/service.py\", line 333, in find_mongod\r\n",
      "    raise ServiceExecutableNotFound(\"Could not find `mongod`\")\r\n",
      "fiftyone.core.service.ServiceExecutableNotFound: Could not find `mongod`\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet-fork/HerdNet/notebooks/../tools/view.py\", line 20, in <module>\r\n",
      "    import fiftyone as fo\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/__init__.py\", line 25, in <module>\r\n",
      "    from fiftyone.__public__ import *\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/__public__.py\", line 14, in <module>\r\n",
      "    foo.establish_db_conn(config)\r\n",
      "  File \"/Users/claudiaagudelo/Documents/Maestria/Cuarto Semestre/Desarrollo de soluciones/HerdNet/.venv/lib/python3.9/site-packages/fiftyone/core/odm/database.py\", line 94, in establish_db_conn\r\n",
      "    raise FiftyOneConfigError(\r\n",
      "fiftyone.core.config.FiftyOneConfigError: MongoDB is not yet supported on Apple Silicon Macs. Please define a `database_uri` in your `fiftyone.core.config.FiftyOneConfig` to define a connection to your own MongoDB instance or cluster\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:41:13.499569Z",
     "start_time": "2025-10-19T21:41:13.472068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {\n",
    "    \"info\": {\n",
    "        \"description\": \"TFE Alexandre Delplanque Training Dataset\",\n",
    "        \"url\": \"None\",\n",
    "        \"version\": \"2.0\",\n",
    "        \"year\": \"2020\",\n",
    "        \"contributor\": \"None\",\n",
    "        \"date_created\": \"2020-11-20\"\n",
    "    },\n",
    "    \"licenses\": [\n",
    "        {\n",
    "            \"url\": \"None\",\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Property of University of Gembloux Agro-Bio Tech\"\n",
    "        },\n",
    "        {\n",
    "            \"url\": \"https://zenodo.org/record/3234780#.XsZ7aGgza01\",\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Naude, Johannes J.; Joubert, Deon\"\n",
    "        }\n",
    "    ],\n",
    "    \"categories\": [\n",
    "        {\n",
    "            \"supercategory\": \"animal\",\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Alcelaphinae\"\n",
    "        },\n",
    "        {\n",
    "            \"supercategory\": \"animal\",\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Buffalo\"\n",
    "        },\n",
    "        {\n",
    "            \"supercategory\": \"animal\",\n",
    "            \"id\": 3,\n",
    "            \"name\": \"Kob\"\n",
    "        },\n",
    "        {\n",
    "            \"supercategory\": \"animal\",\n",
    "            \"id\": 4,\n",
    "            \"name\": \"Warthog\"\n",
    "        },\n",
    "        {\n",
    "            \"supercategory\": \"animal\",\n",
    "            \"id\": 5,\n",
    "            \"name\": \"Waterbuck\"\n",
    "        },\n",
    "        {\n",
    "            \"supercategory\": \"animal\",\n",
    "            \"id\": 6,\n",
    "            \"name\": \"Elephant\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "gt = pd.read_csv(\"patches/valid/gt.csv\")\n",
    "gt"
   ],
   "id": "cb74a5bd31a2e08f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               images  labels  \\\n",
       "0     005c952ba7a612c40986806cc84a87e1573ef4f2_14.JPG       6   \n",
       "1     005c952ba7a612c40986806cc84a87e1573ef4f2_17.JPG       6   \n",
       "2     005c952ba7a612c40986806cc84a87e1573ef4f2_25.JPG       6   \n",
       "3      031833f31b1622ec6701b7433a1664231f401d73_4.JPG       6   \n",
       "4      031833f31b1622ec6701b7433a1664231f401d73_4.JPG       6   \n",
       "...                                               ...     ...   \n",
       "1120                       S_11_05_16_DSC01965_21.JPG       2   \n",
       "1121                       S_11_05_16_DSC01965_21.JPG       2   \n",
       "1122                       S_11_05_16_DSC01965_22.JPG       2   \n",
       "1123                       S_11_05_16_DSC01965_32.JPG       2   \n",
       "1124                       S_11_05_16_DSC01965_32.JPG       2   \n",
       "\n",
       "                                       base_images  x_min  y_min  x_max  y_max  \n",
       "0     005c952ba7a612c40986806cc84a87e1573ef4f2.JPG    327    283    367    335  \n",
       "1     005c952ba7a612c40986806cc84a87e1573ef4f2.JPG     27    282     80    330  \n",
       "2     005c952ba7a612c40986806cc84a87e1573ef4f2.JPG    377    339    423    364  \n",
       "3     031833f31b1622ec6701b7433a1664231f401d73.JPG    295    144    338    181  \n",
       "4     031833f31b1622ec6701b7433a1664231f401d73.JPG    230    275    269    295  \n",
       "...                                            ...    ...    ...    ...    ...  \n",
       "1120                       S_11_05_16_DSC01965.JPG    496    253    512    327  \n",
       "1121                       S_11_05_16_DSC01965.JPG    461    275    509    339  \n",
       "1122                       S_11_05_16_DSC01965.JPG      0    253     34    327  \n",
       "1123                       S_11_05_16_DSC01965.JPG    438     47    511     86  \n",
       "1124                       S_11_05_16_DSC01965.JPG    387     75    475    120  \n",
       "\n",
       "[1125 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>base_images</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005c952ba7a612c40986806cc84a87e1573ef4f2_14.JPG</td>\n",
       "      <td>6</td>\n",
       "      <td>005c952ba7a612c40986806cc84a87e1573ef4f2.JPG</td>\n",
       "      <td>327</td>\n",
       "      <td>283</td>\n",
       "      <td>367</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005c952ba7a612c40986806cc84a87e1573ef4f2_17.JPG</td>\n",
       "      <td>6</td>\n",
       "      <td>005c952ba7a612c40986806cc84a87e1573ef4f2.JPG</td>\n",
       "      <td>27</td>\n",
       "      <td>282</td>\n",
       "      <td>80</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005c952ba7a612c40986806cc84a87e1573ef4f2_25.JPG</td>\n",
       "      <td>6</td>\n",
       "      <td>005c952ba7a612c40986806cc84a87e1573ef4f2.JPG</td>\n",
       "      <td>377</td>\n",
       "      <td>339</td>\n",
       "      <td>423</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>031833f31b1622ec6701b7433a1664231f401d73_4.JPG</td>\n",
       "      <td>6</td>\n",
       "      <td>031833f31b1622ec6701b7433a1664231f401d73.JPG</td>\n",
       "      <td>295</td>\n",
       "      <td>144</td>\n",
       "      <td>338</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>031833f31b1622ec6701b7433a1664231f401d73_4.JPG</td>\n",
       "      <td>6</td>\n",
       "      <td>031833f31b1622ec6701b7433a1664231f401d73.JPG</td>\n",
       "      <td>230</td>\n",
       "      <td>275</td>\n",
       "      <td>269</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>S_11_05_16_DSC01965_21.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>S_11_05_16_DSC01965.JPG</td>\n",
       "      <td>496</td>\n",
       "      <td>253</td>\n",
       "      <td>512</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>S_11_05_16_DSC01965_21.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>S_11_05_16_DSC01965.JPG</td>\n",
       "      <td>461</td>\n",
       "      <td>275</td>\n",
       "      <td>509</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>S_11_05_16_DSC01965_22.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>S_11_05_16_DSC01965.JPG</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>34</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>S_11_05_16_DSC01965_32.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>S_11_05_16_DSC01965.JPG</td>\n",
       "      <td>438</td>\n",
       "      <td>47</td>\n",
       "      <td>511</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>S_11_05_16_DSC01965_32.JPG</td>\n",
       "      <td>2</td>\n",
       "      <td>S_11_05_16_DSC01965.JPG</td>\n",
       "      <td>387</td>\n",
       "      <td>75</td>\n",
       "      <td>475</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1125 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:42:27.065262Z",
     "start_time": "2025-10-19T21:42:27.042778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def convert_bbox_to_coco(bbox):\n",
    "    \"\"\"\n",
    "    Convert bounding box from (x1, y1, x2, y2) format to COCO format (x, y, width, height).\n",
    "\n",
    "    Args:\n",
    "        bbox (list or tuple): Bounding box as [x1, y1, x2, y2] where\n",
    "                              (x1, y1) is top-left corner\n",
    "                              (x2, y2) is bottom-right corner\n",
    "\n",
    "    Returns:\n",
    "        list: Bounding box in COCO format [x, y, width, height]\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    x = x1\n",
    "    y = y1\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "\n",
    "    return [x, y, w, h]"
   ],
   "id": "a7bdea970334639a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:42:29.314865Z",
     "start_time": "2025-10-19T21:42:29.309326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_dataset(patch_dir, gt_csv_path, data_template):\n",
    "    \"\"\"\n",
    "    Process a dataset: extract image dimensions and create COCO annotations.\n",
    "\n",
    "    Args:\n",
    "        patch_dir (str): Directory containing patch images\n",
    "        gt_csv_path (str): Path to ground truth CSV file\n",
    "        data_template (dict): COCO data template with info, licenses, categories\n",
    "\n",
    "    Returns:\n",
    "        dict: Complete COCO format data\n",
    "    \"\"\"\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}\n",
    "    image_dimensions = {}\n",
    "\n",
    "    # Extract image dimensions\n",
    "    dir_path = Path(patch_dir)\n",
    "    image_id_counter = 1\n",
    "    for file_path in dir_path.iterdir():\n",
    "        if file_path.is_file() and file_path.suffix.lower() in image_extensions:\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    width, height = img.size\n",
    "                    image_dimensions[file_path.name] = {\"dims\": (width, height), \"id\": image_id_counter}\n",
    "                    image_id_counter += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path.name}: {e}\")\n",
    "\n",
    "    # Create images list\n",
    "    images = []\n",
    "    for k, v in image_dimensions.items():\n",
    "        images.append({\n",
    "            \"license\": 1,\n",
    "            \"file_name\": k,\n",
    "            \"coco_url\": \"None\",\n",
    "            \"height\": v[\"dims\"][1],\n",
    "            \"width\": v[\"dims\"][0],\n",
    "            \"date_captured\": \"None\",\n",
    "            \"flickr_url\": \"None\",\n",
    "            \"id\": v[\"id\"]\n",
    "        })\n",
    "\n",
    "    # Read ground truth CSV\n",
    "    gt = pd.read_csv(gt_csv_path)\n",
    "\n",
    "    # Create annotations\n",
    "    annotation_id_counter = 1\n",
    "    annotations = []\n",
    "    for index, row in gt.iterrows():\n",
    "        x1, y1, x2, y2 = row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]\n",
    "        bbox = convert_bbox_to_coco([x1, y1, x2, y2])\n",
    "        area = (bbox[2] * bbox[3])\n",
    "        image_id = image_dimensions[row[\"images\"]][\"id\"]\n",
    "        annotations.append({\n",
    "            \"segmentation\": [[]],\n",
    "            \"area\": area,\n",
    "            \"iscrowd\": 0,\n",
    "            \"image_id\": image_id,\n",
    "            \"bbox\": bbox,\n",
    "            \"category_id\": row[\"labels\"],\n",
    "            \"id\": annotation_id_counter\n",
    "        })\n",
    "        annotation_id_counter += 1\n",
    "\n",
    "    # Combine everything\n",
    "    dataset_data = data_template.copy()\n",
    "    dataset_data[\"images\"] = images\n",
    "    dataset_data[\"annotations\"] = annotations\n",
    "\n",
    "    print(f\"Processed {len(images)} images and {len(annotations)} annotations\")\n",
    "\n",
    "    return dataset_data"
   ],
   "id": "f85dcdf580bc0bf2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-19T21:43:47.485496Z",
     "start_time": "2025-10-19T21:43:23.417963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process all three datasets\n",
    "datasets_config = {\n",
    "    \"val\": {\n",
    "        \"patch_dir\": \"./patches/valid\",\n",
    "        \"gt_csv\": \"./patches/valid/gt.csv\",\n",
    "        \"output_json\": \"./patches/valid/_annotations.coco.json\"\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"patch_dir\": \"./patches/train\",\n",
    "        \"gt_csv\": \"./patches/train/gt.csv\",\n",
    "        \"output_json\": \"./patches/train/_annotations.coco.json\"\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"patch_dir\": \"./patches/test\",\n",
    "        \"gt_csv\": \"./patches/test/gt.csv\",\n",
    "        \"output_json\": \"./patches/test/_annotations.coco.json\"\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "for split_name, config in datasets_config.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {split_name.upper()} dataset\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    dataset_data = process_dataset(\n",
    "        patch_dir=config[\"patch_dir\"],\n",
    "        gt_csv_path=config[\"gt_csv\"],\n",
    "        data_template=data\n",
    "    )\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(config[\"output_json\"], \"w\") as f:\n",
    "        json.dump(dataset_data, f, indent=2)\n",
    "\n",
    "    print(f\"Saved to {config['output_json']}\\n\")\n",
    "\n",
    "print(\"All datasets processed successfully!\")"
   ],
   "id": "e37d5214d4a9a8f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing VAL dataset\n",
      "==================================================\n",
      "Processed 10376 images and 1125 annotations\n",
      "Saved to ./annotations_val.json\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing TRAIN dataset\n",
      "==================================================\n",
      "Processed 86968 images and 8207 annotations\n",
      "Saved to ./annotations_train.json\n",
      "\n",
      "\n",
      "==================================================\n",
      "Processing TEST dataset\n",
      "==================================================\n",
      "Processed 23968 images and 2708 annotations\n",
      "Saved to ./annotations_test.json\n",
      "\n",
      "All datasets processed successfully!\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
